[
["index.html", "An Introduction to Statistical Learning What this is about", " An Introduction to Statistical Learning with (Tidy) Applications in R Benjamin Soltoff 2018-07-23 What this is about This book is intended to serve as a companion to An Introduction to Statistical Learning with Applications in R (ISLR) and reimplement the R programs using primarily tidyverse packages and a tidy design philosophy. It is not intended to stand on its own or review the statistical learning concepts from ISLR. It is not intended to teach R programming or computational problem solving in general. For that, I recommend any number of online resources including Hadley Wickhamâ€™s R for Data Science and the materials from my graduate course on Computing for the Social Sciences. The original ISLR book is copyrighted by Springer. The original contribution in work is licensed under the CC BY-NC 4.0 Creative Commons License. "],
["intro.html", "1 Introduction", " 1 Introduction No labs included in this chapter. "],
["stat-learn.html", "2 What is statistical learning? 2.1 What is statistical learning? 2.2 Assessing model accuracy 2.3 Lab: Introduction to R 2.4 Install and load tidyverse packages 2.5 Session information", " 2 What is statistical learning? 2.1 What is statistical learning? 2.2 Assessing model accuracy 2.3 Lab: Introduction to R 2.3.1 Basic commands x &lt;- c(1, 3, 2, 5) x ## [1] 1 3 2 5 Use the assignment operator &lt;- to create new objects in R. Objects can be replaced (or overridden) by creating a new object with the same name. x &lt;- c(1, 6, 2) y &lt;- c(1, 4, 3) x ## [1] 1 6 2 y ## [1] 1 4 3 R performs simple mathematical calculations. For instance, to add numbers use the + notation. This will add the first value of x to the first value of y, and so on. R uses vector recycling if you try to combine vectors that are not the same length, so use length() to confirm that x and y contain the same number of values. length(x) ## [1] 3 length(y) ## [1] 3 x + y ## [1] 2 10 5 Many tidyverse functions will not implicitly perform vector recycling. If you need values or vectors repeated, you will need to explicitly repeat the values first and then run the function. ls() lists the names of all the objects currently in your working environment. ls() ## [1] &quot;x&quot; &quot;y&quot; If you are using RStudio, you can see this list in the upper-right panel of the IDE: RStudio IDE with environment highlighted Most tidyverse functions assume your data is stored in a data frame. A data frame is a spreadsheet style data object which stores values in columns and rows. A tidy data frame adheres to three basic principles: Each variable must have its own column Each observation must have its own row Each value must have its own cell Tibbles are a special type of data frame which work nicely with tidyverse packages and RStudio. To create a tibble, we first need to load the tibble package. Packages in R contain additional functions which build new features onto the base R software. Packages are loaded using the library() function, at which point all the functions in the library are now directly accessible. Use install.packages() if you do not yet have this package installed: install.packages(&quot;tibble&quot;) library(tibble) To create a tibble, we use the tibble() function: tibble( x = 1:5, y = 1, z = x ^ 2 + y ) ## # A tibble: 5 x 3 ## x y z ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 2 ## 2 2 1 5 ## 3 3 1 10 ## 4 4 1 17 ## 5 5 1 26 Each column of a tibble is defined as a vector, and columns can be created either by individual vectors or by recycling inputs of length 1. You can also create variables that are derived from already created columns (hence z). 2.3.2 Graphics ggplot2 is the tidyverse preferred package for generating graphics in R. It is structured on the layered grammar of graphics and provides a consistent syntax for creating both basic and advanced statistical graphs. See the data visualization cheat sheet for a summary of the core graphing functions in ggplot2. For instance, to create a basic scatterplot: # create simulated data scatter_data &lt;- tibble( x = rnorm(100), y = rnorm(100) ) library(ggplot2) # load ggplot2 # generate scatterplot ggplot(data = scatter_data, aes(x = x, y = y)) + geom_point() ggplot2 builds graphs in layers, so additional components are added using the + notation. To add labels to this graph, use the labs() function. ggplot(data = scatter_data, aes(x = x, y = y)) + geom_point() + labs(title = &quot;This is a plot of X vs Y&quot;, x = &quot;This is the x-axis&quot;, y = &quot;This is the y-axis&quot;) To export ggplot() objects, use ggsave(): x &lt;- ggplot(data = scatter_data, aes(x = x, y = y)) + geom_point() + labs(title = &quot;This is a plot of X vs Y&quot;, x = &quot;This is the x-axis&quot;, y = &quot;This is the y-axis&quot;) ggsave(filename = &quot;scatterplot.pdf&quot;, plot = x) ggplot2 is an excellent package for creating static two-dimensional graphs. For interactive or three-dimensional graphs, consider plot.ly or highcharter. 2.3.3 Indexing data Sometimes you want to examine only a portion of a tibble. Beyond the base R [ and [[ subsetting approaches, dplyr provides two core functions for subsetting a data frame. Consider the following tibble: df &lt;- tibble( x = 1:5, y = 1, z = x ^ 2 + y ) df ## # A tibble: 5 x 3 ## x y z ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 2 ## 2 2 1 5 ## 3 3 1 10 ## 4 4 1 17 ## 5 5 1 26 To subset specific rows, use filter(): library(dplyr) ## Warning: package &#39;dplyr&#39; was built under R version 3.5.1 ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union filter(.data = df, x &gt; 3) ## # A tibble: 2 x 3 ## x y z ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4 1 17 ## 2 5 1 26 filter(.data = df, z &lt; 5) ## # A tibble: 1 x 3 ## x y z ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 2 To subset specific columns, use select(): select(.data = df, x, y) ## # A tibble: 5 x 2 ## x y ## &lt;int&gt; &lt;dbl&gt; ## 1 1 1 ## 2 2 1 ## 3 3 1 ## 4 4 1 ## 5 5 1 select(.data = df, -y) ## # A tibble: 5 x 2 ## x z ## &lt;int&gt; &lt;dbl&gt; ## 1 1 2 ## 2 2 5 ## 3 3 10 ## 4 4 17 ## 5 5 26 2.3.4 Loading data To import rectangular data files like .csv or .tsv, use read_csv() or read_tsv() from the readr package: library(readr) Auto &lt;- read_csv(&quot;data/auto.csv&quot;) ## Parsed with column specification: ## cols( ## mpg = col_double(), ## cylinders = col_integer(), ## displacement = col_double(), ## horsepower = col_integer(), ## weight = col_double(), ## acceleration = col_double(), ## year = col_integer(), ## origin = col_integer(), ## name = col_character() ## ) Auto ## # A tibble: 392 x 9 ## mpg cylinders displacement horsepower weight acceleration year origin ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 18 8 307 130 3504 12 70 1 ## 2 15 8 350 165 3693 11.5 70 1 ## 3 18 8 318 150 3436 11 70 1 ## 4 16 8 304 150 3433 12 70 1 ## 5 17 8 302 140 3449 10.5 70 1 ## 6 15 8 429 198 4341 10 70 1 ## # ... with 386 more rows, and 1 more variable: name &lt;chr&gt; read_() functions automatically decode each column type, a header row (if available), and import the data quickly and efficiently. Generally these guesses for column type are accurate, though they can always be manually defined. To import other file types, consider these packages: haven - SAS, SPSS, and Stata readxl - Excel googledrive - Google Sheets 2.3.5 Additional graphical and numerical summaries Variable names are passed to ggplot() using the aes() function. ggplot(data = Auto, aes(x = cylinders, y = mpg)) + geom_point() Since cylinders is essentially a categorical variable (not enough unique values to be considered continuous), we could store it as a qualitative variable using as.factor() and then visualize this data using a boxplot. To convert a column in-place, we use mutate() from the dplyr package: # convert cylinders to a factor variable Auto &lt;- mutate(.data = Auto, cylinders = as.factor(cylinders)) Auto ## # A tibble: 392 x 9 ## mpg cylinders displacement horsepower weight acceleration year origin ## &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 18 8 307 130 3504 12 70 1 ## 2 15 8 350 165 3693 11.5 70 1 ## 3 18 8 318 150 3436 11 70 1 ## 4 16 8 304 150 3433 12 70 1 ## 5 17 8 302 140 3449 10.5 70 1 ## 6 15 8 429 198 4341 10 70 1 ## # ... with 386 more rows, and 1 more variable: name &lt;chr&gt; ggplot(data = Auto, aes(x = cylinders, y = mpg)) + geom_boxplot() The visual appearance of the boxplot can be customized using either additional arguments to geom_boxplot() or adding additional components: ggplot(data = Auto, aes(x = cylinders, y = mpg)) + geom_boxplot(color = &quot;red&quot;) ggplot(data = Auto, aes(x = cylinders, y = mpg)) + geom_boxplot(color = &quot;red&quot;) + labs(x = &quot;Number of cylinders&quot;, y = &quot;MPG&quot;) To create a scatterplot matrix, use ggpairs() from the GGally package: library(GGally) ## ## Attaching package: &#39;GGally&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## nasa ggpairs(data = select(.data = Auto, -name)) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. We need to exclude the name column because it is just an ID column - there is nothing informative in this column to create a scatterplot matrix. We could also write this code using the pipe operator %&gt;% to first subset the tibble, then create the scatterplot matrix: select(.data = Auto, -name) %&gt;% ggpairs() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Piped operations are a powerful tool in the tidyverse to write human-readable code that clearly defines each step of a multi-operation chunk of code. 2.4 Install and load tidyverse packages The easiest method to install and load tidyverse packages is to install tidyverse. This package automatically downloads and installs the complete tidyverse. When you load the package with library(tidyverse), it will automatically load the core tidyverse and make it available in your current R session. The core tidyverse is a set of packages you are likely to use in everyday data analyses. All other tidyverse packages can be loaded directly using library(). install.packages(&quot;tidyverse&quot;) library(tidyverse) ## â”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 1.2.1 â”€â”€ ## âœ” tidyr 0.8.1 âœ” stringr 1.3.1 ## âœ” purrr 0.2.5 âœ” forcats 0.3.0 ## â”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€ ## âœ– dplyr::filter() masks stats::filter() ## âœ– dplyr::lag() masks stats::lag() 2.5 Session information devtools::session_info() ## Session info ------------------------------------------------------------- ## setting value ## version R version 3.5.0 (2018-04-23) ## system x86_64, darwin15.6.0 ## ui X11 ## language (EN) ## collate en_US.UTF-8 ## tz America/Chicago ## date 2018-07-23 ## Packages ----------------------------------------------------------------- ## package * version date source ## backports 1.1.2 2017-12-13 CRAN (R 3.5.0) ## base * 3.5.0 2018-04-24 local ## bookdown 0.7 2018-02-18 CRAN (R 3.5.0) ## compiler 3.5.0 2018-04-24 local ## datasets * 3.5.0 2018-04-24 local ## devtools 1.13.5 2018-02-18 CRAN (R 3.5.0) ## digest 0.6.15 2018-01-28 CRAN (R 3.5.0) ## evaluate 0.10.1 2017-06-24 CRAN (R 3.5.0) ## graphics * 3.5.0 2018-04-24 local ## grDevices * 3.5.0 2018-04-24 local ## hms 0.4.2 2018-03-10 CRAN (R 3.5.0) ## htmltools 0.3.6 2017-04-28 CRAN (R 3.5.0) ## ISLR 1.2 2017-10-20 CRAN (R 3.5.0) ## knitr 1.20 2018-02-20 CRAN (R 3.5.0) ## magrittr 1.5 2014-11-22 CRAN (R 3.5.0) ## memoise 1.1.0 2017-04-21 CRAN (R 3.5.0) ## methods * 3.5.0 2018-04-24 local ## pillar 1.2.3 2018-05-25 CRAN (R 3.5.0) ## pkgconfig 2.0.1 2017-03-21 CRAN (R 3.5.0) ## R6 2.2.2 2017-06-17 CRAN (R 3.5.0) ## Rcpp 0.12.17 2018-05-18 CRAN (R 3.5.0) ## readr * 1.1.1 2017-05-16 CRAN (R 3.5.0) ## rlang 0.2.1 2018-05-30 CRAN (R 3.5.0) ## rmarkdown 1.9 2018-03-01 CRAN (R 3.5.0) ## rprojroot 1.3-2 2018-01-03 CRAN (R 3.5.0) ## stats * 3.5.0 2018-04-24 local ## stringi 1.2.2 2018-05-02 CRAN (R 3.5.0) ## stringr 1.3.1 2018-05-10 CRAN (R 3.5.0) ## tibble 1.4.2 2018-01-22 CRAN (R 3.5.0) ## tools 3.5.0 2018-04-24 local ## utils * 3.5.0 2018-04-24 local ## withr 2.1.2 2018-03-15 CRAN (R 3.5.0) ## xfun 0.1 2018-01-22 CRAN (R 3.5.0) ## yaml 2.1.19 2018-05-01 CRAN (R 3.5.0) "],
["lin-reg.html", "3 Linear regression 3.1 Simple linear regression 3.2 Multiple linear regression 3.3 Other considerations in the regression model 3.4 The marketing plan 3.5 Comparison of linear regression with \\(K\\)-nearest neighbors 3.6 Lab: Linear regression 3.7 Session information", " 3 Linear regression library(tidyverse) ## â”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 1.2.1 â”€â”€ ## âœ” ggplot2 3.0.0 âœ” purrr 0.2.5 ## âœ” tibble 1.4.2 âœ” dplyr 0.7.6 ## âœ” tidyr 0.8.1 âœ” stringr 1.3.1 ## âœ” readr 1.1.1 âœ” forcats 0.3.0 ## Warning: package &#39;dplyr&#39; was built under R version 3.5.1 ## â”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€ ## âœ– dplyr::filter() masks stats::filter() ## âœ– dplyr::lag() masks stats::lag() 3.1 Simple linear regression 3.2 Multiple linear regression 3.3 Other considerations in the regression model 3.4 The marketing plan 3.5 Comparison of linear regression with \\(K\\)-nearest neighbors 3.6 Lab: Linear regression 3.6.1 Libraries ISLR contains several datasets associated with An Introduction to Statistical Learning. MASS also contains a large number of data sets and functions, one of which is used in this lab. However MASS also contains a function called filter(), which would conflict with filter() from dplyr. To avoid this conflict, we can use data() to directly access the data frame without loading the entire MASS package. We then convert this data frame to a tibble using as_tibble() to ensure proper formatting and appearance. library(ISLR) data(Boston, package = &quot;MASS&quot;) Boston &lt;- as_tibble(Boston) Boston ## # A tibble: 506 x 14 ## crim zn indus chas nox rm age dis rad tax ptratio ## * &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.00632 18 2.31 0 0.538 6.58 65.2 4.09 1 296 15.3 ## 2 0.0273 0 7.07 0 0.469 6.42 78.9 4.97 2 242 17.8 ## 3 0.0273 0 7.07 0 0.469 7.18 61.1 4.97 2 242 17.8 ## 4 0.0324 0 2.18 0 0.458 7.00 45.8 6.06 3 222 18.7 ## 5 0.0690 0 2.18 0 0.458 7.15 54.2 6.06 3 222 18.7 ## 6 0.0298 0 2.18 0 0.458 6.43 58.7 6.06 3 222 18.7 ## # ... with 500 more rows, and 3 more variables: black &lt;dbl&gt;, lstat &lt;dbl&gt;, ## # medv &lt;dbl&gt; 3.6.2 Simple linear regression Boston is a dataset of neighborhood statistics for 506 neighborhoods around Boston, Massachusetts. We will attempt to predict medv (median value of owner-occupied homes in $1000s) using 13 predictors such as rm (average number of rooms per house), age (average age of houses), and lstat (percent of households with low socioeconomic status). To estimate a linear regression model in R, use the core lm() function. The syntax is lm(response ~ predictors, data = dataframe), like this: lm_fit &lt;- lm(medv ~ lstat, data = Boston) To view a summary of the linear regression model, the base R approach uses summary(): summary(lm_fit) ## ## Call: ## lm(formula = medv ~ lstat, data = Boston) ## ## Residuals: ## Min 1Q Median 3Q Max ## -15.17 -3.99 -1.32 2.03 24.50 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 34.5538 0.5626 61.4 &lt;2e-16 *** ## lstat -0.9500 0.0387 -24.5 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 6.22 on 504 degrees of freedom ## Multiple R-squared: 0.544, Adjusted R-squared: 0.543 ## F-statistic: 602 on 1 and 504 DF, p-value: &lt;2e-16 This prints some output to the console, including information about the coefficients, standard errors, and overall model statistics. This approach is not tidy because the object containing all this information is not a data frame. Instead, we can use the broom package to summarize and extract key information about statistical models in tidy tibbles. To view summaries about each component of the model (in this case, the regression coefficients), use tidy(): library(broom) tidy(lm_fit) ## term estimate std.error statistic p.value ## 1 (Intercept) 34.55 0.5626 61.4 3.74e-236 ## 2 lstat -0.95 0.0387 -24.5 5.08e-88 glance() returns a tibble with one row of goodness of fit measures and related statistics. glance(lm_fit) ## r.squared adj.r.squared sigma statistic p.value df logLik AIC BIC ## 1 0.544 0.543 6.22 602 5.08e-88 2 -1641 3289 3302 ## deviance df.residual ## 1 19472 504 augment() returns a data frame with one row per observation from the original dataset and adds information such as fitted values, residuals, etc. augment(lm_fit) %&gt;% as_tibble() ## # A tibble: 506 x 9 ## medv lstat .fitted .se.fit .resid .hat .sigma .cooksd .std.resid ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 24 4.98 29.8 0.406 -5.82 0.00426 6.22 0.00189 -0.939 ## 2 21.6 9.14 25.9 0.308 -4.27 0.00246 6.22 0.000582 -0.688 ## 3 34.7 4.03 30.7 0.433 3.97 0.00486 6.22 0.00100 0.641 ## 4 33.4 2.94 31.8 0.467 1.64 0.00564 6.22 0.000198 0.264 ## 5 36.2 5.33 29.5 0.396 6.71 0.00406 6.21 0.00238 1.08 ## 6 28.7 5.21 29.6 0.399 -0.904 0.00413 6.22 0.0000440 -0.146 ## # ... with 500 more rows To visualize the linear regression model, we can use geom_smooth(): ggplot(data = Boston, aes(x = lstat, y = medv)) + geom_point() + geom_smooth(method = &quot;lm&quot;) This not only draws the best fit line but also generates a 95% confidence interval. Visualizing diagnostic plots can also be done using augment() and ggplot(). augment() automatically calculates statistics such as residuals and leverage statistics. augment(lm_fit) %&gt;% ggplot(aes(x = .fitted, y = .resid)) + geom_point() + labs(x = &quot;Fitted value&quot;, y = &quot;Residual&quot;) augment(lm_fit) %&gt;% ggplot(aes(x = .fitted, y = .std.resid)) + geom_point() + labs(x = &quot;Fitted value&quot;, y = &quot;Standardized residual&quot;) augment(lm_fit) %&gt;% ggplot(aes(x = .hat)) + geom_histogram() + labs(x = &quot;Hat value&quot;) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 3.6.3 Multiple linear regression Again we use lm(), now specifying multiple predictors using x1 + x2 + x3 notation. lm_fit &lt;- lm(medv ~ lstat + age, data = Boston) tidy(lm_fit) ## term estimate std.error statistic p.value ## 1 (Intercept) 33.2228 0.7308 45.46 2.94e-180 ## 2 lstat -1.0321 0.0482 -21.42 8.42e-73 ## 3 age 0.0345 0.0122 2.83 4.91e-03 glance(lm_fit) ## r.squared adj.r.squared sigma statistic p.value df logLik AIC BIC ## 1 0.551 0.549 6.17 309 2.98e-88 3 -1638 3283 3300 ## deviance df.residual ## 1 19168 503 To automatically regress on all of the available predictors: lm_fit &lt;- lm(medv ~ ., data = Boston) tidy(lm_fit) ## term estimate std.error statistic p.value ## 1 (Intercept) 3.65e+01 5.10346 7.1441 3.28e-12 ## 2 crim -1.08e-01 0.03286 -3.2865 1.09e-03 ## 3 zn 4.64e-02 0.01373 3.3816 7.78e-04 ## 4 indus 2.06e-02 0.06150 0.3343 7.38e-01 ## 5 chas 2.69e+00 0.86158 3.1184 1.93e-03 ## 6 nox -1.78e+01 3.81974 -4.6513 4.25e-06 ## 7 rm 3.81e+00 0.41793 9.1161 1.98e-18 ## 8 age 6.92e-04 0.01321 0.0524 9.58e-01 ## 9 dis -1.48e+00 0.19945 -7.3980 6.01e-13 ## 10 rad 3.06e-01 0.06635 4.6129 5.07e-06 ## 11 tax -1.23e-02 0.00376 -3.2800 1.11e-03 ## 12 ptratio -9.53e-01 0.13083 -7.2825 1.31e-12 ## 13 black 9.31e-03 0.00269 3.4668 5.73e-04 ## 14 lstat -5.25e-01 0.05072 -10.3471 7.78e-23 glance(lm_fit) ## r.squared adj.r.squared sigma statistic p.value df logLik AIC BIC ## 1 0.741 0.734 4.75 108 6.72e-135 14 -1499 3028 3091 ## deviance df.residual ## 1 11079 492 Use vif() from the car package to calculate variance inflation factors (VIFs). library(car) ## Loading required package: carData ## ## Attaching package: &#39;car&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## recode ## The following object is masked from &#39;package:purrr&#39;: ## ## some vif(lm_fit) ## crim zn indus chas nox rm age dis rad ## 1.79 2.30 3.99 1.07 4.39 1.93 3.10 3.96 7.48 ## tax ptratio black lstat ## 9.01 1.80 1.35 2.94 3.6.4 Interaction terms Use the syntax lstat * age to simultaneously include lstat, age, and the interaction term lstat x age. Never omit constitutive terms. lm(medv ~ lstat * age, data = Boston) %&gt;% tidy() ## term estimate std.error statistic p.value ## 1 (Intercept) 36.088536 1.46984 24.5528 4.91e-88 ## 2 lstat -1.392117 0.16746 -8.3134 8.78e-16 ## 3 age -0.000721 0.01988 -0.0363 9.71e-01 ## 4 lstat:age 0.004156 0.00185 2.2443 2.52e-02 3.6.5 Non-linear transformations of the predictors Add non-linear transformations of predictors using I(x ^ 2) notation. So to add a second-order polynomial term: lm_fit2 &lt;- lm(medv ~ lstat + I(lstat ^ 2), data = Boston) tidy(lm_fit2) ## term estimate std.error statistic p.value ## 1 (Intercept) 42.8620 0.87208 49.1 3.50e-194 ## 2 lstat -2.3328 0.12380 -18.8 2.55e-60 ## 3 I(lstat^2) 0.0435 0.00375 11.6 7.63e-28 Third and higher order terms are best implemented using poly(), which allows you to specify the highest-order term and all lower-order terms are automatically created. lm_fit5 &lt;- lm(medv ~ poly(x = lstat, degree = 5), data = Boston) tidy(lm_fit5) ## term estimate std.error statistic p.value ## 1 (Intercept) 22.5 0.232 97.20 0.00e+00 ## 2 poly(x = lstat, degree = 5)1 -152.5 5.215 -29.24 2.69e-110 ## 3 poly(x = lstat, degree = 5)2 64.2 5.215 12.32 1.25e-30 ## 4 poly(x = lstat, degree = 5)3 -27.1 5.215 -5.19 3.10e-07 ## 5 poly(x = lstat, degree = 5)4 25.5 5.215 4.88 1.42e-06 ## 6 poly(x = lstat, degree = 5)5 -19.3 5.215 -3.69 2.47e-04 3.6.6 Qualitative predictors Examine the CarSeats data in the ISLR library. as_tibble(Carseats) ## # A tibble: 400 x 11 ## Sales CompPrice Income Advertising Population Price ShelveLoc Age ## * &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 9.5 138 73 11 276 120 Bad 42 ## 2 11.2 111 48 16 260 83 Good 65 ## 3 10.1 113 35 10 269 80 Medium 59 ## 4 7.4 117 100 4 466 97 Medium 55 ## 5 4.15 141 64 3 340 128 Bad 38 ## 6 10.8 124 113 13 501 72 Bad 78 ## # ... with 394 more rows, and 3 more variables: Education &lt;dbl&gt;, ## # Urban &lt;fct&gt;, US &lt;fct&gt; While some of the variables are continuous, others such as ShelveLoc (quality of shelf location) are qualitative. ShelveLoc takes on three possible values: Bad, Medium, and Good. Given qualitative variables, R automatically converts them to a series of dummy variables with 0/1 coding: lm_fit &lt;- lm(Sales ~ . + Income:Advertising + Price:Age, data = Carseats) tidy(lm_fit) ## term estimate std.error statistic p.value ## 1 (Intercept) 6.575565 1.008747 6.519 2.22e-10 ## 2 CompPrice 0.092937 0.004118 22.567 1.64e-72 ## 3 Income 0.010894 0.002604 4.183 3.57e-05 ## 4 Advertising 0.070246 0.022609 3.107 2.03e-03 ## 5 Population 0.000159 0.000368 0.433 6.65e-01 ## 6 Price -0.100806 0.007440 -13.549 1.74e-34 ## 7 ShelveLocGood 4.848676 0.152838 31.724 1.38e-109 ## 8 ShelveLocMedium 1.953262 0.125768 15.531 1.34e-42 ## 9 Age -0.057947 0.015951 -3.633 3.18e-04 ## 10 Education -0.020852 0.019613 -1.063 2.88e-01 ## 11 UrbanYes 0.140160 0.112402 1.247 2.13e-01 ## 12 USYes -0.157557 0.148923 -1.058 2.91e-01 ## 13 Income:Advertising 0.000751 0.000278 2.698 7.29e-03 ## 14 Price:Age 0.000107 0.000133 0.801 4.24e-01 3.6.7 Writing functions 3.7 Session information devtools::session_info() ## Session info ------------------------------------------------------------- ## setting value ## version R version 3.5.0 (2018-04-23) ## system x86_64, darwin15.6.0 ## ui X11 ## language (EN) ## collate en_US.UTF-8 ## tz America/Chicago ## date 2018-07-23 ## Packages ----------------------------------------------------------------- ## package * version date source ## backports 1.1.2 2017-12-13 CRAN (R 3.5.0) ## base * 3.5.0 2018-04-24 local ## bookdown 0.7 2018-02-18 CRAN (R 3.5.0) ## compiler 3.5.0 2018-04-24 local ## datasets * 3.5.0 2018-04-24 local ## devtools 1.13.5 2018-02-18 CRAN (R 3.5.0) ## digest 0.6.15 2018-01-28 CRAN (R 3.5.0) ## evaluate 0.10.1 2017-06-24 CRAN (R 3.5.0) ## graphics * 3.5.0 2018-04-24 local ## grDevices * 3.5.0 2018-04-24 local ## htmltools 0.3.6 2017-04-28 CRAN (R 3.5.0) ## knitr 1.20 2018-02-20 CRAN (R 3.5.0) ## magrittr 1.5 2014-11-22 CRAN (R 3.5.0) ## memoise 1.1.0 2017-04-21 CRAN (R 3.5.0) ## methods * 3.5.0 2018-04-24 local ## Rcpp 0.12.17 2018-05-18 CRAN (R 3.5.0) ## rmarkdown 1.9 2018-03-01 CRAN (R 3.5.0) ## rprojroot 1.3-2 2018-01-03 CRAN (R 3.5.0) ## stats * 3.5.0 2018-04-24 local ## stringi 1.2.2 2018-05-02 CRAN (R 3.5.0) ## stringr 1.3.1 2018-05-10 CRAN (R 3.5.0) ## tools 3.5.0 2018-04-24 local ## utils * 3.5.0 2018-04-24 local ## withr 2.1.2 2018-03-15 CRAN (R 3.5.0) ## xfun 0.1 2018-01-22 CRAN (R 3.5.0) ## yaml 2.1.19 2018-05-01 CRAN (R 3.5.0) "]
]
